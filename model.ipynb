{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd1a6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "975bbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "964a9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    " \n",
    "model = FashionMNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dae20eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = get_accuracy(pred, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += accuracy.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        if batch % 100 == 0:\n",
    "            current = batch * len(X)\n",
    "            avg_loss = total_loss / (batch + 1)\n",
    "            avg_accuracy = total_accuracy / (batch + 1) * 100\n",
    "            print(f\"Batch {batch}, Loss: {avg_loss:>7f}, \"\n",
    "                  f\"Accuracy: {avg_accuracy:>0.2f}% \"\n",
    "                  f\"[{current:>5d}/{size:>5d}]\")\n",
    "         if avg_accuracy >= 95:\n",
    "                print(\"Reached 95% accuracy, stopping training.\")\n",
    "                return True\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def get_accuracy(pred, labels):\n",
    "    _, predictions = torch.max(pred, 1)\n",
    "    correct = (predictions == labels).float().sum()\n",
    "    accuracy = correct / labels.shape[0]\n",
    "    return accuracy\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "417c1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Batch 0, Loss: 2.337414, Accuracy: 3.12% [    0/60000]\n",
      "Batch 100, Loss: 0.969327, Accuracy: 67.90% [ 6400/60000]\n",
      "Batch 200, Loss: 0.789062, Accuracy: 73.64% [12800/60000]\n",
      "Batch 300, Loss: 0.708814, Accuracy: 76.01% [19200/60000]\n",
      "Batch 400, Loss: 0.660531, Accuracy: 77.47% [25600/60000]\n",
      "Batch 500, Loss: 0.624799, Accuracy: 78.63% [32000/60000]\n",
      "Batch 600, Loss: 0.599226, Accuracy: 79.41% [38400/60000]\n",
      "Batch 700, Loss: 0.578969, Accuracy: 80.07% [44800/60000]\n",
      "Batch 800, Loss: 0.561633, Accuracy: 80.63% [51200/60000]\n",
      "Batch 900, Loss: 0.550510, Accuracy: 81.02% [57600/60000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.440707, Accuracy: 81.25% [    0/60000]\n",
      "Batch 100, Loss: 0.414023, Accuracy: 85.16% [ 6400/60000]\n",
      "Batch 200, Loss: 0.423252, Accuracy: 84.90% [12800/60000]\n",
      "Batch 300, Loss: 0.416092, Accuracy: 85.21% [19200/60000]\n",
      "Batch 400, Loss: 0.412465, Accuracy: 85.44% [25600/60000]\n",
      "Batch 500, Loss: 0.408444, Accuracy: 85.63% [32000/60000]\n",
      "Batch 600, Loss: 0.409744, Accuracy: 85.60% [38400/60000]\n",
      "Batch 700, Loss: 0.410245, Accuracy: 85.52% [44800/60000]\n",
      "Batch 800, Loss: 0.408541, Accuracy: 85.56% [51200/60000]\n",
      "Batch 900, Loss: 0.404775, Accuracy: 85.68% [57600/60000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.514361, Accuracy: 87.50% [    0/60000]\n",
      "Batch 100, Loss: 0.375703, Accuracy: 86.76% [ 6400/60000]\n",
      "Batch 200, Loss: 0.371836, Accuracy: 86.57% [12800/60000]\n",
      "Batch 300, Loss: 0.371976, Accuracy: 86.55% [19200/60000]\n",
      "Batch 400, Loss: 0.366802, Accuracy: 86.82% [25600/60000]\n",
      "Batch 500, Loss: 0.365399, Accuracy: 86.86% [32000/60000]\n",
      "Batch 600, Loss: 0.363439, Accuracy: 86.90% [38400/60000]\n",
      "Batch 700, Loss: 0.364848, Accuracy: 86.84% [44800/60000]\n",
      "Batch 800, Loss: 0.364308, Accuracy: 86.88% [51200/60000]\n",
      "Batch 900, Loss: 0.361102, Accuracy: 86.97% [57600/60000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.565057, Accuracy: 75.00% [    0/60000]\n",
      "Batch 100, Loss: 0.340593, Accuracy: 87.44% [ 6400/60000]\n",
      "Batch 200, Loss: 0.334918, Accuracy: 87.84% [12800/60000]\n",
      "Batch 300, Loss: 0.331572, Accuracy: 87.95% [19200/60000]\n",
      "Batch 400, Loss: 0.334015, Accuracy: 87.86% [25600/60000]\n",
      "Batch 500, Loss: 0.330615, Accuracy: 88.00% [32000/60000]\n",
      "Batch 600, Loss: 0.331257, Accuracy: 87.98% [38400/60000]\n",
      "Batch 700, Loss: 0.333489, Accuracy: 87.90% [44800/60000]\n",
      "Batch 800, Loss: 0.336153, Accuracy: 87.82% [51200/60000]\n",
      "Batch 900, Loss: 0.335471, Accuracy: 87.86% [57600/60000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.291833, Accuracy: 89.06% [    0/60000]\n",
      "Batch 100, Loss: 0.314532, Accuracy: 88.77% [ 6400/60000]\n",
      "Batch 200, Loss: 0.310470, Accuracy: 88.67% [12800/60000]\n",
      "Batch 300, Loss: 0.310001, Accuracy: 88.73% [19200/60000]\n",
      "Batch 400, Loss: 0.313203, Accuracy: 88.61% [25600/60000]\n",
      "Batch 500, Loss: 0.310813, Accuracy: 88.64% [32000/60000]\n",
      "Batch 600, Loss: 0.310203, Accuracy: 88.62% [38400/60000]\n",
      "Batch 700, Loss: 0.311560, Accuracy: 88.59% [44800/60000]\n",
      "Batch 800, Loss: 0.312810, Accuracy: 88.52% [51200/60000]\n",
      "Batch 900, Loss: 0.314306, Accuracy: 88.47% [57600/60000]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.266905, Accuracy: 87.50% [    0/60000]\n",
      "Batch 100, Loss: 0.289981, Accuracy: 89.40% [ 6400/60000]\n",
      "Batch 200, Loss: 0.291132, Accuracy: 89.48% [12800/60000]\n",
      "Batch 300, Loss: 0.293474, Accuracy: 89.41% [19200/60000]\n",
      "Batch 400, Loss: 0.293222, Accuracy: 89.39% [25600/60000]\n",
      "Batch 500, Loss: 0.293351, Accuracy: 89.37% [32000/60000]\n",
      "Batch 600, Loss: 0.295090, Accuracy: 89.28% [38400/60000]\n",
      "Batch 700, Loss: 0.295447, Accuracy: 89.20% [44800/60000]\n",
      "Batch 800, Loss: 0.296210, Accuracy: 89.23% [51200/60000]\n",
      "Batch 900, Loss: 0.296128, Accuracy: 89.20% [57600/60000]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.230814, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.255888, Accuracy: 90.58% [ 6400/60000]\n",
      "Batch 200, Loss: 0.262271, Accuracy: 90.38% [12800/60000]\n",
      "Batch 300, Loss: 0.272334, Accuracy: 90.12% [19200/60000]\n",
      "Batch 400, Loss: 0.276217, Accuracy: 89.99% [25600/60000]\n",
      "Batch 500, Loss: 0.277782, Accuracy: 89.94% [32000/60000]\n",
      "Batch 600, Loss: 0.279934, Accuracy: 89.89% [38400/60000]\n",
      "Batch 700, Loss: 0.282731, Accuracy: 89.82% [44800/60000]\n",
      "Batch 800, Loss: 0.283958, Accuracy: 89.73% [51200/60000]\n",
      "Batch 900, Loss: 0.283508, Accuracy: 89.74% [57600/60000]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.328969, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.268916, Accuracy: 90.04% [ 6400/60000]\n",
      "Batch 200, Loss: 0.270173, Accuracy: 90.04% [12800/60000]\n",
      "Batch 300, Loss: 0.271577, Accuracy: 89.86% [19200/60000]\n",
      "Batch 400, Loss: 0.275145, Accuracy: 89.81% [25600/60000]\n",
      "Batch 500, Loss: 0.272911, Accuracy: 89.86% [32000/60000]\n",
      "Batch 600, Loss: 0.270064, Accuracy: 89.98% [38400/60000]\n",
      "Batch 700, Loss: 0.271587, Accuracy: 90.04% [44800/60000]\n",
      "Batch 800, Loss: 0.272898, Accuracy: 90.00% [51200/60000]\n",
      "Batch 900, Loss: 0.273365, Accuracy: 89.96% [57600/60000]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.166377, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.262915, Accuracy: 90.21% [ 6400/60000]\n",
      "Batch 200, Loss: 0.264499, Accuracy: 90.26% [12800/60000]\n",
      "Batch 300, Loss: 0.264802, Accuracy: 90.25% [19200/60000]\n",
      "Batch 400, Loss: 0.264570, Accuracy: 90.27% [25600/60000]\n",
      "Batch 500, Loss: 0.263445, Accuracy: 90.34% [32000/60000]\n",
      "Batch 600, Loss: 0.264741, Accuracy: 90.27% [38400/60000]\n",
      "Batch 700, Loss: 0.265126, Accuracy: 90.22% [44800/60000]\n",
      "Batch 800, Loss: 0.263995, Accuracy: 90.28% [51200/60000]\n",
      "Batch 900, Loss: 0.263983, Accuracy: 90.23% [57600/60000]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.204028, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.235898, Accuracy: 91.24% [ 6400/60000]\n",
      "Batch 200, Loss: 0.241111, Accuracy: 90.95% [12800/60000]\n",
      "Batch 300, Loss: 0.249196, Accuracy: 90.78% [19200/60000]\n",
      "Batch 400, Loss: 0.250984, Accuracy: 90.80% [25600/60000]\n",
      "Batch 500, Loss: 0.252010, Accuracy: 90.74% [32000/60000]\n",
      "Batch 600, Loss: 0.254171, Accuracy: 90.63% [38400/60000]\n",
      "Batch 700, Loss: 0.254921, Accuracy: 90.63% [44800/60000]\n",
      "Batch 800, Loss: 0.255208, Accuracy: 90.58% [51200/60000]\n",
      "Batch 900, Loss: 0.253631, Accuracy: 90.65% [57600/60000]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.284696, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.238052, Accuracy: 91.20% [ 6400/60000]\n",
      "Batch 200, Loss: 0.245066, Accuracy: 90.87% [12800/60000]\n",
      "Batch 300, Loss: 0.247059, Accuracy: 90.78% [19200/60000]\n",
      "Batch 400, Loss: 0.243794, Accuracy: 90.87% [25600/60000]\n",
      "Batch 500, Loss: 0.243926, Accuracy: 90.92% [32000/60000]\n",
      "Batch 600, Loss: 0.244763, Accuracy: 90.93% [38400/60000]\n",
      "Batch 700, Loss: 0.246612, Accuracy: 90.82% [44800/60000]\n",
      "Batch 800, Loss: 0.247174, Accuracy: 90.84% [51200/60000]\n",
      "Batch 900, Loss: 0.246275, Accuracy: 90.88% [57600/60000]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.287721, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.229663, Accuracy: 91.20% [ 6400/60000]\n",
      "Batch 200, Loss: 0.237743, Accuracy: 90.99% [12800/60000]\n",
      "Batch 300, Loss: 0.241135, Accuracy: 90.82% [19200/60000]\n",
      "Batch 400, Loss: 0.239814, Accuracy: 90.96% [25600/60000]\n",
      "Batch 500, Loss: 0.238307, Accuracy: 91.13% [32000/60000]\n",
      "Batch 600, Loss: 0.238277, Accuracy: 91.12% [38400/60000]\n",
      "Batch 700, Loss: 0.238487, Accuracy: 91.15% [44800/60000]\n",
      "Batch 800, Loss: 0.237310, Accuracy: 91.20% [51200/60000]\n",
      "Batch 900, Loss: 0.238000, Accuracy: 91.12% [57600/60000]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.234120, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.238642, Accuracy: 91.38% [ 6400/60000]\n",
      "Batch 200, Loss: 0.230149, Accuracy: 91.75% [12800/60000]\n",
      "Batch 300, Loss: 0.232964, Accuracy: 91.52% [19200/60000]\n",
      "Batch 400, Loss: 0.229601, Accuracy: 91.65% [25600/60000]\n",
      "Batch 500, Loss: 0.227787, Accuracy: 91.71% [32000/60000]\n",
      "Batch 600, Loss: 0.228428, Accuracy: 91.57% [38400/60000]\n",
      "Batch 700, Loss: 0.228671, Accuracy: 91.56% [44800/60000]\n",
      "Batch 800, Loss: 0.231170, Accuracy: 91.48% [51200/60000]\n",
      "Batch 900, Loss: 0.231850, Accuracy: 91.42% [57600/60000]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.214185, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.228986, Accuracy: 91.52% [ 6400/60000]\n",
      "Batch 200, Loss: 0.226522, Accuracy: 91.52% [12800/60000]\n",
      "Batch 300, Loss: 0.224753, Accuracy: 91.51% [19200/60000]\n",
      "Batch 400, Loss: 0.226062, Accuracy: 91.48% [25600/60000]\n",
      "Batch 500, Loss: 0.227180, Accuracy: 91.48% [32000/60000]\n",
      "Batch 600, Loss: 0.225471, Accuracy: 91.56% [38400/60000]\n",
      "Batch 700, Loss: 0.224934, Accuracy: 91.60% [44800/60000]\n",
      "Batch 800, Loss: 0.224201, Accuracy: 91.61% [51200/60000]\n",
      "Batch 900, Loss: 0.224888, Accuracy: 91.53% [57600/60000]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.211408, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.219285, Accuracy: 91.77% [ 6400/60000]\n",
      "Batch 200, Loss: 0.221112, Accuracy: 91.81% [12800/60000]\n",
      "Batch 300, Loss: 0.223814, Accuracy: 91.74% [19200/60000]\n",
      "Batch 400, Loss: 0.220414, Accuracy: 91.79% [25600/60000]\n",
      "Batch 500, Loss: 0.217861, Accuracy: 91.92% [32000/60000]\n",
      "Batch 600, Loss: 0.217164, Accuracy: 91.90% [38400/60000]\n",
      "Batch 700, Loss: 0.216418, Accuracy: 91.93% [44800/60000]\n",
      "Batch 800, Loss: 0.217882, Accuracy: 91.88% [51200/60000]\n",
      "Batch 900, Loss: 0.219211, Accuracy: 91.84% [57600/60000]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.104297, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.209152, Accuracy: 92.31% [ 6400/60000]\n",
      "Batch 200, Loss: 0.203139, Accuracy: 92.55% [12800/60000]\n",
      "Batch 300, Loss: 0.206190, Accuracy: 92.28% [19200/60000]\n",
      "Batch 400, Loss: 0.207789, Accuracy: 92.27% [25600/60000]\n",
      "Batch 500, Loss: 0.207231, Accuracy: 92.30% [32000/60000]\n",
      "Batch 600, Loss: 0.207850, Accuracy: 92.23% [38400/60000]\n",
      "Batch 700, Loss: 0.211585, Accuracy: 92.11% [44800/60000]\n",
      "Batch 800, Loss: 0.211791, Accuracy: 92.06% [51200/60000]\n",
      "Batch 900, Loss: 0.212158, Accuracy: 92.03% [57600/60000]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.167200, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.201624, Accuracy: 92.56% [ 6400/60000]\n",
      "Batch 200, Loss: 0.204143, Accuracy: 92.52% [12800/60000]\n",
      "Batch 300, Loss: 0.206845, Accuracy: 92.41% [19200/60000]\n",
      "Batch 400, Loss: 0.204700, Accuracy: 92.46% [25600/60000]\n",
      "Batch 500, Loss: 0.206134, Accuracy: 92.39% [32000/60000]\n",
      "Batch 600, Loss: 0.206424, Accuracy: 92.35% [38400/60000]\n",
      "Batch 700, Loss: 0.206015, Accuracy: 92.31% [44800/60000]\n",
      "Batch 800, Loss: 0.205498, Accuracy: 92.30% [51200/60000]\n",
      "Batch 900, Loss: 0.207183, Accuracy: 92.26% [57600/60000]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.341458, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.194251, Accuracy: 92.85% [ 6400/60000]\n",
      "Batch 200, Loss: 0.191328, Accuracy: 92.90% [12800/60000]\n",
      "Batch 300, Loss: 0.189682, Accuracy: 92.99% [19200/60000]\n",
      "Batch 400, Loss: 0.192469, Accuracy: 92.90% [25600/60000]\n",
      "Batch 500, Loss: 0.196243, Accuracy: 92.73% [32000/60000]\n",
      "Batch 600, Loss: 0.197906, Accuracy: 92.63% [38400/60000]\n",
      "Batch 700, Loss: 0.199922, Accuracy: 92.56% [44800/60000]\n",
      "Batch 800, Loss: 0.201467, Accuracy: 92.53% [51200/60000]\n",
      "Batch 900, Loss: 0.202005, Accuracy: 92.50% [57600/60000]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.098288, Accuracy: 98.44% [    0/60000]\n",
      "Batch 100, Loss: 0.199335, Accuracy: 92.81% [ 6400/60000]\n",
      "Batch 200, Loss: 0.192732, Accuracy: 92.99% [12800/60000]\n",
      "Batch 300, Loss: 0.192735, Accuracy: 92.92% [19200/60000]\n",
      "Batch 400, Loss: 0.193987, Accuracy: 92.87% [25600/60000]\n",
      "Batch 500, Loss: 0.194705, Accuracy: 92.84% [32000/60000]\n",
      "Batch 600, Loss: 0.197332, Accuracy: 92.70% [38400/60000]\n",
      "Batch 700, Loss: 0.197671, Accuracy: 92.69% [44800/60000]\n",
      "Batch 800, Loss: 0.199104, Accuracy: 92.62% [51200/60000]\n",
      "Batch 900, Loss: 0.198646, Accuracy: 92.63% [57600/60000]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.220228, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.202028, Accuracy: 92.51% [ 6400/60000]\n",
      "Batch 200, Loss: 0.195241, Accuracy: 92.80% [12800/60000]\n",
      "Batch 300, Loss: 0.193691, Accuracy: 92.87% [19200/60000]\n",
      "Batch 400, Loss: 0.191669, Accuracy: 92.93% [25600/60000]\n",
      "Batch 500, Loss: 0.192002, Accuracy: 92.91% [32000/60000]\n",
      "Batch 600, Loss: 0.190992, Accuracy: 92.92% [38400/60000]\n",
      "Batch 700, Loss: 0.192412, Accuracy: 92.80% [44800/60000]\n",
      "Batch 800, Loss: 0.192790, Accuracy: 92.82% [51200/60000]\n",
      "Batch 900, Loss: 0.193602, Accuracy: 92.80% [57600/60000]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.156754, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.188157, Accuracy: 92.96% [ 6400/60000]\n",
      "Batch 200, Loss: 0.187416, Accuracy: 92.97% [12800/60000]\n",
      "Batch 300, Loss: 0.185539, Accuracy: 93.06% [19200/60000]\n",
      "Batch 400, Loss: 0.189053, Accuracy: 93.00% [25600/60000]\n",
      "Batch 500, Loss: 0.186300, Accuracy: 93.10% [32000/60000]\n",
      "Batch 600, Loss: 0.187957, Accuracy: 93.04% [38400/60000]\n",
      "Batch 700, Loss: 0.187646, Accuracy: 93.01% [44800/60000]\n",
      "Batch 800, Loss: 0.187645, Accuracy: 93.00% [51200/60000]\n",
      "Batch 900, Loss: 0.189142, Accuracy: 92.95% [57600/60000]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.157502, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.192750, Accuracy: 92.68% [ 6400/60000]\n",
      "Batch 200, Loss: 0.185559, Accuracy: 93.14% [12800/60000]\n",
      "Batch 300, Loss: 0.180465, Accuracy: 93.24% [19200/60000]\n",
      "Batch 400, Loss: 0.180112, Accuracy: 93.33% [25600/60000]\n",
      "Batch 500, Loss: 0.179846, Accuracy: 93.36% [32000/60000]\n",
      "Batch 600, Loss: 0.180323, Accuracy: 93.32% [38400/60000]\n",
      "Batch 700, Loss: 0.182331, Accuracy: 93.24% [44800/60000]\n",
      "Batch 800, Loss: 0.183740, Accuracy: 93.19% [51200/60000]\n",
      "Batch 900, Loss: 0.185028, Accuracy: 93.13% [57600/60000]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.151174, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.177555, Accuracy: 93.33% [ 6400/60000]\n",
      "Batch 200, Loss: 0.179940, Accuracy: 93.27% [12800/60000]\n",
      "Batch 300, Loss: 0.177507, Accuracy: 93.38% [19200/60000]\n",
      "Batch 400, Loss: 0.178435, Accuracy: 93.37% [25600/60000]\n",
      "Batch 500, Loss: 0.179141, Accuracy: 93.41% [32000/60000]\n",
      "Batch 600, Loss: 0.177653, Accuracy: 93.41% [38400/60000]\n",
      "Batch 700, Loss: 0.178075, Accuracy: 93.34% [44800/60000]\n",
      "Batch 800, Loss: 0.179636, Accuracy: 93.29% [51200/60000]\n",
      "Batch 900, Loss: 0.178898, Accuracy: 93.29% [57600/60000]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.068422, Accuracy: 98.44% [    0/60000]\n",
      "Batch 100, Loss: 0.168454, Accuracy: 93.50% [ 6400/60000]\n",
      "Batch 200, Loss: 0.171119, Accuracy: 93.46% [12800/60000]\n",
      "Batch 300, Loss: 0.170690, Accuracy: 93.56% [19200/60000]\n",
      "Batch 400, Loss: 0.171230, Accuracy: 93.54% [25600/60000]\n",
      "Batch 500, Loss: 0.172132, Accuracy: 93.52% [32000/60000]\n",
      "Batch 600, Loss: 0.173311, Accuracy: 93.48% [38400/60000]\n",
      "Batch 700, Loss: 0.173470, Accuracy: 93.48% [44800/60000]\n",
      "Batch 800, Loss: 0.175380, Accuracy: 93.42% [51200/60000]\n",
      "Batch 900, Loss: 0.175648, Accuracy: 93.46% [57600/60000]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.067470, Accuracy: 98.44% [    0/60000]\n",
      "Batch 100, Loss: 0.159609, Accuracy: 94.26% [ 6400/60000]\n",
      "Batch 200, Loss: 0.159030, Accuracy: 94.29% [12800/60000]\n",
      "Batch 300, Loss: 0.163428, Accuracy: 94.04% [19200/60000]\n",
      "Batch 400, Loss: 0.163939, Accuracy: 93.95% [25600/60000]\n",
      "Batch 500, Loss: 0.164724, Accuracy: 93.95% [32000/60000]\n",
      "Batch 600, Loss: 0.166700, Accuracy: 93.84% [38400/60000]\n",
      "Batch 700, Loss: 0.167523, Accuracy: 93.80% [44800/60000]\n",
      "Batch 800, Loss: 0.168986, Accuracy: 93.73% [51200/60000]\n",
      "Batch 900, Loss: 0.170024, Accuracy: 93.69% [57600/60000]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.338179, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.176060, Accuracy: 93.66% [ 6400/60000]\n",
      "Batch 200, Loss: 0.171213, Accuracy: 93.69% [12800/60000]\n",
      "Batch 300, Loss: 0.167072, Accuracy: 93.73% [19200/60000]\n",
      "Batch 400, Loss: 0.165926, Accuracy: 93.80% [25600/60000]\n",
      "Batch 500, Loss: 0.166229, Accuracy: 93.78% [32000/60000]\n",
      "Batch 600, Loss: 0.165241, Accuracy: 93.87% [38400/60000]\n",
      "Batch 700, Loss: 0.166023, Accuracy: 93.85% [44800/60000]\n",
      "Batch 800, Loss: 0.166989, Accuracy: 93.76% [51200/60000]\n",
      "Batch 900, Loss: 0.165856, Accuracy: 93.87% [57600/60000]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.233741, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.169404, Accuracy: 93.60% [ 6400/60000]\n",
      "Batch 200, Loss: 0.159701, Accuracy: 93.82% [12800/60000]\n",
      "Batch 300, Loss: 0.164500, Accuracy: 93.77% [19200/60000]\n",
      "Batch 400, Loss: 0.162317, Accuracy: 93.77% [25600/60000]\n",
      "Batch 500, Loss: 0.162805, Accuracy: 93.85% [32000/60000]\n",
      "Batch 600, Loss: 0.162727, Accuracy: 93.90% [38400/60000]\n",
      "Batch 700, Loss: 0.163072, Accuracy: 93.87% [44800/60000]\n",
      "Batch 800, Loss: 0.165586, Accuracy: 93.81% [51200/60000]\n",
      "Batch 900, Loss: 0.165347, Accuracy: 93.84% [57600/60000]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.162737, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.151385, Accuracy: 94.40% [ 6400/60000]\n",
      "Batch 200, Loss: 0.152964, Accuracy: 94.43% [12800/60000]\n",
      "Batch 300, Loss: 0.159298, Accuracy: 94.14% [19200/60000]\n",
      "Batch 400, Loss: 0.159846, Accuracy: 94.14% [25600/60000]\n",
      "Batch 500, Loss: 0.161447, Accuracy: 94.11% [32000/60000]\n",
      "Batch 600, Loss: 0.159916, Accuracy: 94.12% [38400/60000]\n",
      "Batch 700, Loss: 0.161654, Accuracy: 94.05% [44800/60000]\n",
      "Batch 800, Loss: 0.161385, Accuracy: 94.09% [51200/60000]\n",
      "Batch 900, Loss: 0.161931, Accuracy: 94.06% [57600/60000]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.110804, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.158823, Accuracy: 94.04% [ 6400/60000]\n",
      "Batch 200, Loss: 0.155895, Accuracy: 94.15% [12800/60000]\n",
      "Batch 300, Loss: 0.154474, Accuracy: 94.23% [19200/60000]\n",
      "Batch 400, Loss: 0.153959, Accuracy: 94.27% [25600/60000]\n",
      "Batch 500, Loss: 0.158146, Accuracy: 94.04% [32000/60000]\n",
      "Batch 600, Loss: 0.156403, Accuracy: 94.11% [38400/60000]\n",
      "Batch 700, Loss: 0.157038, Accuracy: 94.10% [44800/60000]\n",
      "Batch 800, Loss: 0.156507, Accuracy: 94.12% [51200/60000]\n",
      "Batch 900, Loss: 0.156275, Accuracy: 94.11% [57600/60000]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.113602, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.143759, Accuracy: 94.42% [ 6400/60000]\n",
      "Batch 200, Loss: 0.144566, Accuracy: 94.52% [12800/60000]\n",
      "Batch 300, Loss: 0.149332, Accuracy: 94.50% [19200/60000]\n",
      "Batch 400, Loss: 0.151035, Accuracy: 94.51% [25600/60000]\n",
      "Batch 500, Loss: 0.150220, Accuracy: 94.48% [32000/60000]\n",
      "Batch 600, Loss: 0.153968, Accuracy: 94.36% [38400/60000]\n",
      "Batch 700, Loss: 0.156145, Accuracy: 94.28% [44800/60000]\n",
      "Batch 800, Loss: 0.155554, Accuracy: 94.26% [51200/60000]\n",
      "Batch 900, Loss: 0.154631, Accuracy: 94.29% [57600/60000]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.282798, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.132354, Accuracy: 95.16% [ 6400/60000]\n",
      "Batch 200, Loss: 0.143694, Accuracy: 94.66% [12800/60000]\n",
      "Batch 300, Loss: 0.145234, Accuracy: 94.59% [19200/60000]\n",
      "Batch 400, Loss: 0.146488, Accuracy: 94.47% [25600/60000]\n",
      "Batch 500, Loss: 0.146545, Accuracy: 94.52% [32000/60000]\n",
      "Batch 600, Loss: 0.148761, Accuracy: 94.47% [38400/60000]\n",
      "Batch 700, Loss: 0.148876, Accuracy: 94.45% [44800/60000]\n",
      "Batch 800, Loss: 0.151071, Accuracy: 94.40% [51200/60000]\n",
      "Batch 900, Loss: 0.151506, Accuracy: 94.36% [57600/60000]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.234852, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.132023, Accuracy: 95.20% [ 6400/60000]\n",
      "Batch 200, Loss: 0.133053, Accuracy: 95.11% [12800/60000]\n",
      "Batch 300, Loss: 0.140847, Accuracy: 94.82% [19200/60000]\n",
      "Batch 400, Loss: 0.141950, Accuracy: 94.82% [25600/60000]\n",
      "Batch 500, Loss: 0.143783, Accuracy: 94.67% [32000/60000]\n",
      "Batch 600, Loss: 0.144574, Accuracy: 94.64% [38400/60000]\n",
      "Batch 700, Loss: 0.145638, Accuracy: 94.59% [44800/60000]\n",
      "Batch 800, Loss: 0.145548, Accuracy: 94.60% [51200/60000]\n",
      "Batch 900, Loss: 0.145519, Accuracy: 94.62% [57600/60000]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.151981, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.147300, Accuracy: 94.83% [ 6400/60000]\n",
      "Batch 200, Loss: 0.141630, Accuracy: 95.04% [12800/60000]\n",
      "Batch 300, Loss: 0.137393, Accuracy: 95.12% [19200/60000]\n",
      "Batch 400, Loss: 0.138423, Accuracy: 95.05% [25600/60000]\n",
      "Batch 500, Loss: 0.140354, Accuracy: 94.97% [32000/60000]\n",
      "Batch 600, Loss: 0.139290, Accuracy: 95.00% [38400/60000]\n",
      "Batch 700, Loss: 0.139777, Accuracy: 94.89% [44800/60000]\n",
      "Batch 800, Loss: 0.139882, Accuracy: 94.88% [51200/60000]\n",
      "Batch 900, Loss: 0.141806, Accuracy: 94.80% [57600/60000]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.131309, Accuracy: 92.19% [    0/60000]\n",
      "Batch 100, Loss: 0.132088, Accuracy: 95.13% [ 6400/60000]\n",
      "Batch 200, Loss: 0.135210, Accuracy: 94.90% [12800/60000]\n",
      "Batch 300, Loss: 0.136237, Accuracy: 94.92% [19200/60000]\n",
      "Batch 400, Loss: 0.137432, Accuracy: 94.81% [25600/60000]\n",
      "Batch 500, Loss: 0.135832, Accuracy: 94.92% [32000/60000]\n",
      "Batch 600, Loss: 0.136829, Accuracy: 94.90% [38400/60000]\n",
      "Batch 700, Loss: 0.138001, Accuracy: 94.80% [44800/60000]\n",
      "Batch 800, Loss: 0.139773, Accuracy: 94.74% [51200/60000]\n",
      "Batch 900, Loss: 0.140012, Accuracy: 94.73% [57600/60000]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.045473, Accuracy: 100.00% [    0/60000]\n",
      "Batch 100, Loss: 0.132306, Accuracy: 94.97% [ 6400/60000]\n",
      "Batch 200, Loss: 0.134790, Accuracy: 94.95% [12800/60000]\n",
      "Batch 300, Loss: 0.135267, Accuracy: 95.05% [19200/60000]\n",
      "Batch 400, Loss: 0.135370, Accuracy: 95.10% [25600/60000]\n",
      "Batch 500, Loss: 0.134379, Accuracy: 95.02% [32000/60000]\n",
      "Batch 600, Loss: 0.136130, Accuracy: 94.89% [38400/60000]\n",
      "Batch 700, Loss: 0.137168, Accuracy: 94.86% [44800/60000]\n",
      "Batch 800, Loss: 0.137467, Accuracy: 94.87% [51200/60000]\n",
      "Batch 900, Loss: 0.137755, Accuracy: 94.86% [57600/60000]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.101289, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.121526, Accuracy: 95.45% [ 6400/60000]\n",
      "Batch 200, Loss: 0.124309, Accuracy: 95.28% [12800/60000]\n",
      "Batch 300, Loss: 0.127832, Accuracy: 95.20% [19200/60000]\n",
      "Batch 400, Loss: 0.127924, Accuracy: 95.19% [25600/60000]\n",
      "Batch 500, Loss: 0.132763, Accuracy: 95.01% [32000/60000]\n",
      "Batch 600, Loss: 0.134111, Accuracy: 95.01% [38400/60000]\n",
      "Batch 700, Loss: 0.135005, Accuracy: 94.96% [44800/60000]\n",
      "Batch 800, Loss: 0.135967, Accuracy: 94.97% [51200/60000]\n",
      "Batch 900, Loss: 0.135191, Accuracy: 94.97% [57600/60000]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.242645, Accuracy: 90.62% [    0/60000]\n",
      "Batch 100, Loss: 0.114525, Accuracy: 95.99% [ 6400/60000]\n",
      "Batch 200, Loss: 0.125179, Accuracy: 95.68% [12800/60000]\n",
      "Batch 300, Loss: 0.126162, Accuracy: 95.58% [19200/60000]\n",
      "Batch 400, Loss: 0.129007, Accuracy: 95.37% [25600/60000]\n",
      "Batch 500, Loss: 0.129375, Accuracy: 95.25% [32000/60000]\n",
      "Batch 600, Loss: 0.131733, Accuracy: 95.15% [38400/60000]\n",
      "Batch 700, Loss: 0.132365, Accuracy: 95.15% [44800/60000]\n",
      "Batch 800, Loss: 0.132183, Accuracy: 95.14% [51200/60000]\n",
      "Batch 900, Loss: 0.133117, Accuracy: 95.10% [57600/60000]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.160103, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.130099, Accuracy: 95.19% [ 6400/60000]\n",
      "Batch 200, Loss: 0.133685, Accuracy: 95.14% [12800/60000]\n",
      "Batch 300, Loss: 0.133956, Accuracy: 95.09% [19200/60000]\n",
      "Batch 400, Loss: 0.134663, Accuracy: 95.04% [25600/60000]\n",
      "Batch 500, Loss: 0.131860, Accuracy: 95.15% [32000/60000]\n",
      "Batch 600, Loss: 0.131936, Accuracy: 95.23% [38400/60000]\n",
      "Batch 700, Loss: 0.132149, Accuracy: 95.21% [44800/60000]\n",
      "Batch 800, Loss: 0.131757, Accuracy: 95.22% [51200/60000]\n",
      "Batch 900, Loss: 0.130985, Accuracy: 95.22% [57600/60000]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.153799, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.120847, Accuracy: 95.54% [ 6400/60000]\n",
      "Batch 200, Loss: 0.126060, Accuracy: 95.34% [12800/60000]\n",
      "Batch 300, Loss: 0.127639, Accuracy: 95.26% [19200/60000]\n",
      "Batch 400, Loss: 0.125828, Accuracy: 95.34% [25600/60000]\n",
      "Batch 500, Loss: 0.125507, Accuracy: 95.35% [32000/60000]\n",
      "Batch 600, Loss: 0.125868, Accuracy: 95.36% [38400/60000]\n",
      "Batch 700, Loss: 0.126284, Accuracy: 95.38% [44800/60000]\n",
      "Batch 800, Loss: 0.126545, Accuracy: 95.37% [51200/60000]\n",
      "Batch 900, Loss: 0.126558, Accuracy: 95.39% [57600/60000]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.196457, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.115047, Accuracy: 95.70% [ 6400/60000]\n",
      "Batch 200, Loss: 0.117872, Accuracy: 95.51% [12800/60000]\n",
      "Batch 300, Loss: 0.119686, Accuracy: 95.56% [19200/60000]\n",
      "Batch 400, Loss: 0.120354, Accuracy: 95.57% [25600/60000]\n",
      "Batch 500, Loss: 0.120170, Accuracy: 95.59% [32000/60000]\n",
      "Batch 600, Loss: 0.121309, Accuracy: 95.53% [38400/60000]\n",
      "Batch 700, Loss: 0.121953, Accuracy: 95.50% [44800/60000]\n",
      "Batch 800, Loss: 0.122210, Accuracy: 95.44% [51200/60000]\n",
      "Batch 900, Loss: 0.123398, Accuracy: 95.42% [57600/60000]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.104239, Accuracy: 98.44% [    0/60000]\n",
      "Batch 100, Loss: 0.115266, Accuracy: 96.06% [ 6400/60000]\n",
      "Batch 200, Loss: 0.116007, Accuracy: 95.91% [12800/60000]\n",
      "Batch 300, Loss: 0.123084, Accuracy: 95.51% [19200/60000]\n",
      "Batch 400, Loss: 0.121486, Accuracy: 95.52% [25600/60000]\n",
      "Batch 500, Loss: 0.118046, Accuracy: 95.66% [32000/60000]\n",
      "Batch 600, Loss: 0.118807, Accuracy: 95.58% [38400/60000]\n",
      "Batch 700, Loss: 0.118953, Accuracy: 95.56% [44800/60000]\n",
      "Batch 800, Loss: 0.121264, Accuracy: 95.42% [51200/60000]\n",
      "Batch 900, Loss: 0.122161, Accuracy: 95.43% [57600/60000]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.120122, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.118590, Accuracy: 95.71% [ 6400/60000]\n",
      "Batch 200, Loss: 0.120859, Accuracy: 95.53% [12800/60000]\n",
      "Batch 300, Loss: 0.116990, Accuracy: 95.63% [19200/60000]\n",
      "Batch 400, Loss: 0.119619, Accuracy: 95.54% [25600/60000]\n",
      "Batch 500, Loss: 0.120772, Accuracy: 95.55% [32000/60000]\n",
      "Batch 600, Loss: 0.118814, Accuracy: 95.64% [38400/60000]\n",
      "Batch 700, Loss: 0.119020, Accuracy: 95.63% [44800/60000]\n",
      "Batch 800, Loss: 0.120554, Accuracy: 95.54% [51200/60000]\n",
      "Batch 900, Loss: 0.120282, Accuracy: 95.54% [57600/60000]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.081339, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.103349, Accuracy: 96.19% [ 6400/60000]\n",
      "Batch 200, Loss: 0.112686, Accuracy: 95.93% [12800/60000]\n",
      "Batch 300, Loss: 0.113644, Accuracy: 95.72% [19200/60000]\n",
      "Batch 400, Loss: 0.113545, Accuracy: 95.80% [25600/60000]\n",
      "Batch 500, Loss: 0.114502, Accuracy: 95.73% [32000/60000]\n",
      "Batch 600, Loss: 0.115484, Accuracy: 95.70% [38400/60000]\n",
      "Batch 700, Loss: 0.116586, Accuracy: 95.68% [44800/60000]\n",
      "Batch 800, Loss: 0.115666, Accuracy: 95.72% [51200/60000]\n",
      "Batch 900, Loss: 0.116793, Accuracy: 95.66% [57600/60000]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.121385, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.114038, Accuracy: 95.87% [ 6400/60000]\n",
      "Batch 200, Loss: 0.115439, Accuracy: 95.73% [12800/60000]\n",
      "Batch 300, Loss: 0.113730, Accuracy: 95.87% [19200/60000]\n",
      "Batch 400, Loss: 0.110282, Accuracy: 95.94% [25600/60000]\n",
      "Batch 500, Loss: 0.111657, Accuracy: 95.91% [32000/60000]\n",
      "Batch 600, Loss: 0.112160, Accuracy: 95.89% [38400/60000]\n",
      "Batch 700, Loss: 0.112962, Accuracy: 95.85% [44800/60000]\n",
      "Batch 800, Loss: 0.112629, Accuracy: 95.83% [51200/60000]\n",
      "Batch 900, Loss: 0.112911, Accuracy: 95.83% [57600/60000]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.036031, Accuracy: 100.00% [    0/60000]\n",
      "Batch 100, Loss: 0.116748, Accuracy: 95.62% [ 6400/60000]\n",
      "Batch 200, Loss: 0.108832, Accuracy: 95.97% [12800/60000]\n",
      "Batch 300, Loss: 0.111061, Accuracy: 95.88% [19200/60000]\n",
      "Batch 400, Loss: 0.112306, Accuracy: 95.78% [25600/60000]\n",
      "Batch 500, Loss: 0.112732, Accuracy: 95.81% [32000/60000]\n",
      "Batch 600, Loss: 0.111815, Accuracy: 95.84% [38400/60000]\n",
      "Batch 700, Loss: 0.111001, Accuracy: 95.89% [44800/60000]\n",
      "Batch 800, Loss: 0.112519, Accuracy: 95.82% [51200/60000]\n",
      "Batch 900, Loss: 0.114224, Accuracy: 95.76% [57600/60000]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.090246, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.101092, Accuracy: 96.18% [ 6400/60000]\n",
      "Batch 200, Loss: 0.103308, Accuracy: 96.11% [12800/60000]\n",
      "Batch 300, Loss: 0.107104, Accuracy: 95.95% [19200/60000]\n",
      "Batch 400, Loss: 0.109166, Accuracy: 95.85% [25600/60000]\n",
      "Batch 500, Loss: 0.107260, Accuracy: 96.00% [32000/60000]\n",
      "Batch 600, Loss: 0.108719, Accuracy: 95.96% [38400/60000]\n",
      "Batch 700, Loss: 0.108792, Accuracy: 95.95% [44800/60000]\n",
      "Batch 800, Loss: 0.108109, Accuracy: 95.99% [51200/60000]\n",
      "Batch 900, Loss: 0.108971, Accuracy: 95.95% [57600/60000]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.265276, Accuracy: 89.06% [    0/60000]\n",
      "Batch 100, Loss: 0.102846, Accuracy: 96.29% [ 6400/60000]\n",
      "Batch 200, Loss: 0.105749, Accuracy: 95.99% [12800/60000]\n",
      "Batch 300, Loss: 0.103852, Accuracy: 96.08% [19200/60000]\n",
      "Batch 400, Loss: 0.103312, Accuracy: 96.11% [25600/60000]\n",
      "Batch 500, Loss: 0.104471, Accuracy: 96.10% [32000/60000]\n",
      "Batch 600, Loss: 0.104948, Accuracy: 96.08% [38400/60000]\n",
      "Batch 700, Loss: 0.106835, Accuracy: 96.04% [44800/60000]\n",
      "Batch 800, Loss: 0.107840, Accuracy: 95.97% [51200/60000]\n",
      "Batch 900, Loss: 0.107687, Accuracy: 95.99% [57600/60000]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.115518, Accuracy: 93.75% [    0/60000]\n",
      "Batch 100, Loss: 0.109897, Accuracy: 95.92% [ 6400/60000]\n",
      "Batch 200, Loss: 0.105582, Accuracy: 96.07% [12800/60000]\n",
      "Batch 300, Loss: 0.104843, Accuracy: 96.19% [19200/60000]\n",
      "Batch 400, Loss: 0.104961, Accuracy: 96.22% [25600/60000]\n",
      "Batch 500, Loss: 0.104172, Accuracy: 96.26% [32000/60000]\n",
      "Batch 600, Loss: 0.104868, Accuracy: 96.21% [38400/60000]\n",
      "Batch 700, Loss: 0.105560, Accuracy: 96.15% [44800/60000]\n",
      "Batch 800, Loss: 0.105793, Accuracy: 96.14% [51200/60000]\n",
      "Batch 900, Loss: 0.106088, Accuracy: 96.12% [57600/60000]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.081663, Accuracy: 96.88% [    0/60000]\n",
      "Batch 100, Loss: 0.095981, Accuracy: 96.43% [ 6400/60000]\n",
      "Batch 200, Loss: 0.098457, Accuracy: 96.39% [12800/60000]\n",
      "Batch 300, Loss: 0.101587, Accuracy: 96.23% [19200/60000]\n",
      "Batch 400, Loss: 0.101884, Accuracy: 96.23% [25600/60000]\n",
      "Batch 500, Loss: 0.103923, Accuracy: 96.16% [32000/60000]\n",
      "Batch 600, Loss: 0.103894, Accuracy: 96.18% [38400/60000]\n",
      "Batch 700, Loss: 0.104549, Accuracy: 96.12% [44800/60000]\n",
      "Batch 800, Loss: 0.105726, Accuracy: 96.06% [51200/60000]\n",
      "Batch 900, Loss: 0.105676, Accuracy: 96.05% [57600/60000]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Batch 0, Loss: 0.069431, Accuracy: 95.31% [    0/60000]\n",
      "Batch 100, Loss: 0.096493, Accuracy: 96.24% [ 6400/60000]\n",
      "Batch 200, Loss: 0.097763, Accuracy: 96.28% [12800/60000]\n",
      "Batch 300, Loss: 0.097642, Accuracy: 96.34% [19200/60000]\n",
      "Batch 400, Loss: 0.097964, Accuracy: 96.32% [25600/60000]\n",
      "Batch 500, Loss: 0.099248, Accuracy: 96.29% [32000/60000]\n",
      "Batch 600, Loss: 0.099581, Accuracy: 96.30% [38400/60000]\n",
      "Batch 700, Loss: 0.100426, Accuracy: 96.28% [44800/60000]\n",
      "Batch 800, Loss: 0.100981, Accuracy: 96.28% [51200/60000]\n",
      "Batch 900, Loss: 0.101398, Accuracy: 96.26% [57600/60000]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training process\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_function, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb0d4ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.435063 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == \n",
    "                        y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    " \n",
    "# Evaluate the model\n",
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4253c240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4240e+01, -4.0967e+01, -2.6300e+01, -2.6986e+01, -3.0091e+01,\n",
      "         -1.5191e+01, -2.7613e+01, -9.5765e+00, -3.2009e+01, -6.9616e-05]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted 9, and the actual label is 9.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "def predict_single_image(image, label, model):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    " \n",
    "# Unsqueeze image as the model expects a batch dimension\n",
    "    image = image.unsqueeze(0)\n",
    " \n",
    "    with torch.no_grad():\n",
    "        prediction = model(image)\n",
    "        print(prediction)\n",
    "        predicted_label = prediction.argmax(1).item()\n",
    " \n",
    "    # Display the image and predictions\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(f'Predicted: {predicted_label}, Actual: {label}')\n",
    "    plt.show()\n",
    " \n",
    "    return predicted_label\n",
    " \n",
    "# Choose an image from the test set\n",
    "image, label = test_dataset[0]  # Change index to test different images\n",
    " \n",
    "# Predict the class for the chosen image\n",
    "predicted_label = predict_single_image(image, label, model)\n",
    "print(f\"The model predicted {predicted_label}, and the actual label is {label}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
